# General Collective Communications Library

+-----------------------+
|     DeviceManager     | → 硬件抽象（GPU/昇腾等）
+-----------------------+
|   TopologyBuilder     | → 创建TP/PP组，管理物理拓扑
+-----------------------+
|    Communicator       | → 核心通信接口（点对点/集合通信）
+-----------------------+
|      StreamPool       | → 异步通信流管理
+-----------------------+
| Compression/SerDe     | → 数据压缩与序列化
+-----------------------+



## 接口：
1. 初始化与环境管理

|接口|参数|解释|
|---|---|---|
|Init||负责初始化通信环境，分配必要资源，配置网络、硬件加速器和拓扑信息。|
|Finalize||释放资源、关闭网络连接，并确保所有通信操作完成后安全退出。|
|Comm_rank||获取当前进程在通信组中的编号。|
|Finalize||查询当前通信组中进程的总数。|

2. 点对点通信接口

|接口|参数|解释|
|---|---|---|
|Send||阻塞式发送数据，适合数据量较小、延迟要求较低的场景。|
|Recv||阻塞式接收数据。|
|Isend||非阻塞发送数据，允许重叠计算与通信。|
|Irecv||非阻塞式接收数据。|
|Wait||等待异步操作完成。|
|Test||查询异步操作的状态。|

3. 集体通信接口
|接口|参数|解释|
|---|---|---|
|GCCL_Broadcast||广播：root 节点向所有节点发送同一份数据|
|GCCL_Reduce||归约：将所有节点的输入数据进行 op 操作，并将结果存放到 root 节点的 recvbuf|
|GCCL_Allreduce||全局归约：将所有节点的输入数据进行 op 操作，结果广播到所有节点|
|GCCL_Allgather||所有收集：各节点发送自己的数据到 root 并拼成一块，然后再广播到所有节点|
|GCCL_Scatter||分发：root 节点将一大块数据拆分给多个节点（每节点一块）|
|GCCL_Gather||收集：各节点将数据发送到 root，root 将它们依次拼接|
|GCCL_Barrier||屏障：等待所有节点到达此处再继续|

4. 通信组与拓扑管理
组管理接口
GCCL_Comm_split：将全局通信组划分为若干子组，便于针对特定任务或拓扑优化。
GCCL_Comm_create：动态创建新的通信组，支持层次化和自适应的通信拓扑。

5. 错误处理与异常管理
错误检测与反馈

每个接口均应返回详细的错误码或异常信息，便于用户定位问题。
GCCL_Error_string：将错误码转换为易读的错误描述。
容错与重传机制

在底层实现中加入自动重传、超时检测与节点心跳监测，确保在部分节点故障情况下系统能自动恢复。
6. 性能监控与调优接口
性能指标查询
GCCL_Get_performance_metrics：提供实时数据传输延迟、吞吐量、错误率等关键性能指标。
针对性能瓶颈设计实时告警机制，辅助用户调优通信策略。
7. 异步通信与回调机制
非阻塞操作支持
提供异步接口的同时，允许用户注册回调函数，在通信操作完成后触发特定动作，以支持高性能场景下的任务调度与事件驱动编程。




GCCL 在定位于“大语言模型分布式训练与推理”的背景下，可以综合以上方案优点：

* 通过可插拔模块应对异构硬件和不同网络协议；
* 在集体通信层面尽量提供常用且关键的操作（Allreduce/Allgather/Broadcast 等）；
* 重视容错与错误处理机制；
* 整合 GPU 优化策略与拓扑感知能力；
* 提供简洁易用的上层接口。

## 明确需求与目标
### 应用场景与目标定位：
我设计的通信库要解决哪些问题：单节点内通信（负责大语言模型并行计算TP时的数据分发与收集等操作）、节点间通信（负责大语言模型并行计算PP时的数据发送）需要满足低延迟高吞吐量。
### 功能需求
1. 通信模式支持

点对点通信

提供低延迟、可靠的直接消息传输接口。
支持阻塞与非阻塞通信模式，便于开发者根据场景选择最优方案。

集体通信

广播（Broadcast）：单个节点的数据能高效传递到所有其他节点。
规约（Reduce）：支持多节点数据的归约计算（如求和、最大值、最小值等），并保证计算的正确性与一致性。
全聚集（Allgather）：每个节点都能获取所有节点的数据，适合模型参数的全局同步。
可扩展其他常用集体操作，如Scatter、Gather以及Barrier同步。

2. 性能优化

低延迟与高吞吐量
优化数据传输通道和协议，支持异步通信以重叠计算与传输。
针对大规模数据和高频通信场景进行硬件加速支持（如共享内存、RDMA、Infiniband等）。

3. 错误处理与异常管理

错误检测

实现传输过程中的错误检测机制，如超时检测、数据校验等，确保数据完整性。
重传与恢复机制
在通信过程中出现错误时能自动重传或给出明确的错误提示。

异常管理

提供详细的错误日志与诊断接口，便于定位问题并进行调试。

4. 数据同步与一致性保障

同步机制

实现全局屏障（Barrier）等同步原语，确保不同计算阶段数据的一致性。
在集体操作中确保数据在各节点间按照预期顺序传递与处理。

5. 容错机制

节点故障检测与恢复

设计容错策略，如定期心跳检测，及时发现节点失效。
支持部分节点失败情况下的数据自动恢复或计算迁移（例如基于检查点机制）。
通信链路的动态恢复
当网络连接临时中断时，能自动重连，并保证数据不丢失或重复传输。

6. 可扩展性与灵活性

模块化设计

将不同通信模式和功能模块解耦，使得后续扩展（例如增加新型集体操作或支持新网络协议）更为容易。

接口友好性

提供清晰、易用的API，同时支持跨平台和多语言绑定（如C/C++、Python等）。


## 架构设计与模块划分
### 架构总览
GCCL 的设计核心在于将复杂的通信需求拆分为多个独立而又协同工作的模块，每个模块聚焦于特定功能，既保证了高性能（低延迟、高吞吐量），也便于后续扩展与维护。整体架构可大致分为以下几个层次：

底层网络通信层：直接封装底层网络接口和硬件相关的驱动，支持共享内存、RDMA、Infiniband 等多种传输方式。

抽象接口层：为上层提供统一的 API 接口，屏蔽底层实现细节。该层负责同步与异步通信模式的封装，以及参数校验和简单错误处理。

通信管理与调度层：负责整体通信的初始化、资源管理、通信组管理以及任务调度。通过内部调度器实现任务的高效排队与调度，同时集成错误检测、超时机制与恢复策略。

性能监控与调优模块：设计监控机制（如实时日志、性能指标采集、延迟与吞吐量统计），及时定位性能瓶颈，为后续调优提供数据支撑。

API设计与多语言支持：将核心功能封装成易用的 API，同时提供跨平台与多语言绑定（如 C/C++、Python 等），保证接口清晰、简洁且灵活。

### 模块详细设计
#### 底层网络通信层
功能描述，该层直接与硬件或系统网络栈交互，完成数据包的组装、发送和接收。主要任务包括：
* 封装不同网络协议（TCP/IP、RDMA等）；
* 适配各种硬件加速方式；
* 处理数据传输中的低级错误与重传机制。

设计要点
* 支持多种传输模式（同步/异步）；
* 模块化设计，方便在遇到新硬件或新协议时通过插件机制扩展；
* 保证接口高效，避免过多复制与额外开销。
#### 抽象接口层
功能描述，对上层应用暴露统一的调用接口，屏蔽底层的实现细节，简化开发者使用。
* 提供点对点通信和集体通信的统一接口；
* 封装阻塞与非阻塞的操作模式；
* 简化错误码和异常信息的传递。

设计要点
* 接口文档应详细说明每个操作的语义；
* 考虑线程安全性与并发访问；
* 预留扩展接口，以便后续增加新的集体通信操作（如Scatter、Gather、Barrier）。
#### 通信管理与调度层
功能描述，作为整个通信系统的“大脑”，负责系统资源的分配、通信任务的调度和错误管理。
* 初始化和配置整个通信系统；
* 维护通信组，管理节点间连接与拓扑结构；
* 实现任务调度器，支持通信任务的优先级和并发控制；
* 负责错误监测、超时处理和自动恢复（包括重传机制）。
设计要点
* 采用模块化调度策略，可根据节点负载、网络状态动态调整任务分配；
* 提供详细的错误日志和诊断接口，便于定位问题；
* 支持集群中部分节点失效时的容错策略，如基于心跳检测和检查点恢复的机制。

#### 性能监控与调优模块
功能描述，实时监控通信过程中的性能指标和瓶颈，反馈信息以便动态调优。
* 采集数据传输延迟、吞吐量、错误率等指标；
* 定时生成报告并提供实时告警机制；
* 提供接口允许外部调优工具接入。
设计要点
* 设计轻量级监控，不影响数据传输性能；
* 对关键路径进行细粒度性能记录；
* 支持自定义扩展，方便后续整合新型硬件监控能力。

#### API设计与多语言支持
功能描述,将以上核心功能模块封装为对用户友好的接口，支持跨平台调用。
* 设计简洁、统一的 API，覆盖所有通信模式（点对点和集体通信）；
* 同时支持同步与异步调用；
* 提供详细的错误返回机制和文档说明。
设计要点
* 接口命名规范、参数设计一致，降低学习曲线；
* 考虑与现有分布式训练框架的集成，如与 CUDA、NCCL 或 MPI 的互操作；
* 保证 API 的稳定性和向后兼容性，同时预留版本升级路径；
### 综合设计与扩展策略
模块化与插件化设计
各模块间采用松耦合设计，既能独立升级，也方便在新需求（如新增网络协议或硬件加速器）出现时，通过插件方式无缝扩展。

容错与错误处理
在通信管理层和底层网络层中均要设计详细的错误处理流程，保证在异常情况下系统能自动重试、快速恢复或转移任务，避免因单节点或链路故障导致整体中断。

性能与安全监控
性能监控模块不仅用于调优，也可以辅助安全检测，例如在数据校验和错误监控中检测异常流量或恶意干扰行为，为分布式训练过程提供多重保障。

跨平台与多语言支持
在 API 设计时，充分考虑平台差异和语言边界问题，通过 C/C++ 核心实现保证性能，再通过语言绑定（如 Python 扩展模块）提升开发效率和应用范围。