我在设计大语言模型的推理引擎，C++ 实现，支持多节点多卡并行计算，节点内 TP + PP，节点间只 PP。

* Server 使用 engine.add_request() 添加请求，随即 Engine 内部进行运算，每一轮的 step 存到某个队列内，由 Server 自行取用。
* Engine 利用 Scheduler 将 request 组成 request_batch 送给 Worker。（Scheduler 负责决策，Engine 负责根据决策准备 ModelInputBatch（包含 tokens, Block Tables 等）并分发给 Worker(s)。）
* Worker 利用 Communicator 和 Layer 进行节点内的 TP 计算（Worker 执行其拥有的 Layer，而这些 Layer 如果是张量并行的，会使用注入的 IntraNodeTensorParallelCommunicator 来进行 TP 组内部的通信（如 AllReduce, AllGather）。）
* Worker 完成其节点内的 TP 计算后，将其（作为流水线一个阶段的）输出结果报告/返回给其所在节点的 Engine
* 不同节点上的 Engine 实例之间。一个节点的 Engine (我们称之为 Engine_A，负责阶段 S) 在收到其内部 Worker 的结果后，会使用 InterNodePipelineCommunicator 将这个结果 Send 给负责下一个阶段 S+1 的另一个节点上的 Engine (我们称之为 Engine_B)。同样，Engine_B 会使用这个 Communicator 来 Recv 来自 Engine_A 的数据。

**阶段一：构思与规划 (Idea & Planning)**

1.  **明确想法与目标 (Define Idea & Goals):**
    *   **核心功能:** 大语言模型推理引擎
    *   **目标用户:** 中国使用国产计算卡的小型企业、个人、实验室
    *   **价值主张:** 大吞吐、高速、异构
    *   **范围界定 (Scope):** 初期版本仅支持核心token推理，日后再实现Server部分。

2.  **市场调研与竞品分析 (Market Research & Competitor Analysis):** 
    *   **现有产品:** SGLang、vLLM、TensorRT-LLM、MindIE、[llama.cpp]。
    *   **差异化和优势:** 见现有产品调研。

3.  **需求分析 (Requirements Analysis):**
    *   **功能需求:** 系统必须具备模型参数装载、单节点多卡推理、多节点多卡推理。
    *   **非功能需求:** 1）吞吐量（Throughput）
、首Token时延（TTFT, Time to First Token）、每Token生成时延（TPOT, Time Per Output Token）；2）显存占用（GPU Memory Usage）；3）可扩展性（可扩展到多设备，模块内技术替换）；4）可维护性（计算卡掉线）。
    *   **约束条件:** 开发语言（C++）、目标平台（Linux）、依赖的硬件（NVIDIA GPU、NPU、MOSS）、时间限制（5个月）等。

4.  **可行性分析 (Feasibility Study):**
    *   **技术可行性:** 现有框架对于开发者来说存在众多技术难点。
    *   **资源可行性:** 人力紧张（只有作者一个人）；时间紧张（年底完成）。
    *   **风险评估:** 存在可能无法攻克技术点的情况，也有可能在开发中出现新的框架技术直接让本产品失去存在意义。技术问题只能花时间去硬啃，出现新产品的话就装鸵鸟，假装看不见。

**阶段二：设计 (Design)**

1.  **架构设计 (Architectural Design):**
    *   **高层架构:** 分层架构
    *   **模块划分:** 
        * **Server:** 与用户交互（本版本不实现）
        * **Engine:** 进行模型 token 推理，不断自回归生成数据
        * **InterNodeComm:** 进行 Engine 之间的数据通信，相当于节点间进行流水线并行。
        * **Scheduler:** Engine 内调度子模块，负责调度用户请求，选择哪些请求进入 Engine 当前计算轮次。
        * **Worker:** Engine 内真正用于计算子模块，Engine 维护多个 Worker 进行张量并行计算（TP）。每个 Worker 负责管理一个外部设备进行内存管理、计算。
        * **Layer:** 用于 Worker 内的函数运算，下面有Function，根据 Worker 提供的设备类型，选取对应的函数装备。
        * **Function:** 抽象接口，是 Layer 调用的具体函数，负责实际的计算，跟据不同的设备有不同的实现。
        * **MemAllocator:** 负责管理 Worker 的设备内存，提供给 Layer 的参数（Weight）以及运算过程中产生的中间值（Activation）。
        * **KVCacheManager:** 负责管理 Worker 设备计算过程中产生的 KVCache，应该是需要协同 MemAllocator 一同工作。

2.  **详细设计 (Detailed Design):**
    *   **类设计:** 设计核心类，包括其属性、方法、继承关系、组合关系。可以考虑使用UML类图。
    *   **接口设计 (API Design):** 模块间、类间的接口。力求清晰、稳定、易用。
    *   **算法设计:** FlashAttention、blockAttention、MemPool、microBatch、
    *   **错误处理与日志策略:** GPU掉线处理（本版本不实现）Timeout 异常、记录日志。

3.  **原型开发 (Prototyping):** (可选，但推荐)
    *   针对核心功能或高风险模块开发一个快速原型，用于验证技术方案、设计思路或用户界面。

**阶段三：实现 (Implementation)**

1.  **环境搭建 (Environment Setup):**
    *   **IDE/编辑器:** Visual Studio, CLion, VS Code, Qt Creator等。
    *   **编译器:** MSVC, GCC, Clang。
    *   **构建系统:** CMake (强烈推荐，跨平台), Make, Meson, Bazel等。
    *   **版本控制系统:** Git (几乎是标配)。
    *   **包管理器:** Conan, vcpkg (用于管理第三方依赖)。
    *   **调试工具:** GDB, LLDB, Visual Studio Debugger。

2.  **编码 (Coding):**
    *   **遵循编码规范:** 统一代码风格，提高可读性和可维护性（例如 Google C++ Style Guide, LLVM Coding Standards）。
    *   **模块化开发:** 根据设计，分模块进行开发。
    *   **面向对象/泛型编程:** 充分利用C++的特性。
    *   **内存管理:** 使用RAII原则，智能指针 (std::unique_ptr, std::shared_ptr) 来避免内存泄漏。
    *   **异常安全:** 编写异常安全的代码。
    *   **代码复用:** 避免重复造轮子，合理使用库和模板。
    *   **单元测试驱动开发 (TDD) / 并行编写单元测试:** 为每个模块或重要函数编写单元测试。使用测试框架如 Google Test, Catch2。

3.  **代码审查 (Code Review):**
    *   团队成员互相审查代码，发现潜在问题，提高代码质量，知识共享。

4.  **集成 (Integration):**
    *   逐步将各个模块集成起来，解决集成过程中出现的问题。
    *   **持续集成 (CI):** 使用 Jenkins, GitLab CI/CD, GitHub Actions 等工具，在代码提交后自动构建、测试。

**阶段四：测试 (Testing)**

1.  **单元测试 (Unit Testing):** 验证最小代码单元（函数、类）的正确性。
2.  **集成测试 (Integration Testing):** 验证模块之间交互的正确性。
3.  **系统测试 (System Testing):** 在完整系统环境下，验证系统是否满足所有需求（功能和非功能）。
4.  **用户验收测试 (UAT - User Acceptance Testing):** 由最终用户或代表进行测试，确认项目是否满足其期望。
5.  **性能测试、安全测试、压力测试等:** 根据非功能需求进行。
6.  **Bug修复:** 记录、跟踪并修复测试过程中发现的缺陷。

**阶段五：部署 (Deployment)**

1.  **准备部署环境:** 生产服务器、操作系统、依赖库等。
2.  **打包与分发:**
    *   **编译发布版本 (Release Build):** 开启优化，关闭调试信息。
    *   **创建安装包:** 使用 NSIS, Inno Setup (Windows), CPack (CMake自带) 等。
    *   **容器化:** 使用 Docker 将应用及其依赖打包成镜像。
3.  **部署上线:** 将应用部署到生产环境。
4.  **配置管理:** 管理不同环境（开发、测试、生产）的配置。
5.  **上线后监控:** 监控系统运行状态、性能指标、错误日志。

**阶段六：维护与迭代 (Maintenance & Iteration)**

1.  **监控与日志分析:** 持续监控系统运行，分析日志，及时发现问题。
2.  **Bug修复:** 修复用户反馈的或监控发现的Bug。
3.  **用户支持:** 提供用户手册、FAQ，解答用户疑问。
4.  **性能优化:** 根据实际运行情况，对瓶颈进行优化。
5.  **功能迭代:** 根据用户反馈和新的业务需求，规划并开发新版本，重复上述2-5阶段。
6.  **文档更新:** 随着代码的变更，及时更新设计文档、用户手册等。

**贯穿始终的重要事项:**

*   **版本控制 (Version Control):** 从项目开始就使用Git，并遵循良好的分支策略（如Gitflow）。
*   **项目管理 (Project Management):**
    *   **方法论:** 选择合适的项目管理方法（敏捷如Scrum/Kanban，或瀑布，或混合）。
    *   **工具:** Jira, Trello, Asana, Redmine等。
    *   **沟通:** 保持团队内外良好沟通。
*   **文档编写 (Documentation):**
    *   **需求文档、设计文档、API文档、用户手册、运维手册。**
    *   **代码注释。**
    *   使用Doxygen等工具从代码生成文档。
*   **持续学习 (Continuous Learning):** C++语言本身在不断发展，新的库和工具也层出不穷，保持学习非常重要。
*   **关注代码质量:** 使用静态分析工具 (Clang-Tidy, Cppcheck, PVS-Studio)、代码格式化工具 (Clang-Format)、代码覆盖率工具。

这个流程是一个理想化的模型，实际项目中可能会根据具体情况进行调整和裁剪。对于小型个人项目，某些步骤可能会简化，但核心思想是相通的。祝你的C++项目顺利！


# Worker、Layer以及Function的设计

在我们的推理引擎中， Worker 、 Layer 和 Function 是核心的计算执行单元。为了实现高效、可扩展且硬件无关的推理能力，我们采用了分层和依赖抽象的设计原则。

核心设计理念：
- Worker 驱动执行与资源管理： Worker 负责管理一个特定的计算设备（如一个 GPU 卡）。它根据 Engine 的调度指令，获取相应的 Layer ，并为其配备合适的 Function 实例来执行计算。 Worker 还负责管理设备的内存（通过 MemAllocator ）和 KV 缓存（通过 KVCacheManager ）。
- Layer 依赖于抽象，而非具体实现： Layer及其子类定义了神经网络中各种标准操作（如线性变换层、注意力层、归一化层等）的接口。它不关心这些操作在具体硬件上如何执行，也不关心使用的数据类型。
- Function 作为具体实现的载体： Function 是 Layer 调用接口的具体实现。针对不同的硬件架构（如 CPU、CUDA GPU、国产 NPU 等）和不同的数据精度（如 FP32、FP16、BF16、INT8 等），会有不同的 Function 实现。

动态注册与选择机制 (Registry Pattern)：

考虑到 Function 的实现组合数量可能非常庞大（硬件类型 x 数据精度 x 操作类型），我们采用了一种灵活且动态的 注册表模式 (Registry Pattern) 来管理这些实现。

核心思想：

1. 全局注册表 ( OpRegistry )： 我们在`registry.h`创建了一个全局的单例注册表管理器，名为 OpRegistry 。这个管理器内部为每一种操作类型（如 Linear 、 Attention 、 RMSNorm 、 Add 等）维护一个专门的函数指针注册表 ( FuncRegistry )。
   
   - FuncRegistry 是一个模板类，它使用 std::map 将一个由 (设备类型, 数据类型) 组成的元组映射到一个具体的函数指针。
   - OpRegistry 提供了访问特定操作类型注册表的接口，例如 OpRegistry::Instance().Linear() 返回 Linear 操作的 FuncRegistry 实例。

2. Function 实现的自动注册： 每个具体的 Function 实现（例如，在 `linear_cuda.cu` 中实现的 cuda_fp32_linear_exec 函数）在程序启动时，通过一个宏 REGISTER_OP_FUNCTION 将自己注册到 OpRegistry 中。
   
   - REGISTER_OP_FUNCTION(OP_NAME, DEVICE, DTYPE, FUNC_PTR) 宏会自动创建一个静态的注册器实例。这个注册器在构造时，会调用 OpRegistry::Instance().OP_NAME().Register(DEVICE, DTYPE, FUNC_PTR) ，将函数指针 FUNC_PTR 与指定的操作名 OP_NAME 、设备类型 DEVICE （如 CUDA ）和数据类型 DTYPE （如 FLOAT32 ）关联起来。
   - 例如，在 `linear_cuda.cu` 中的 REGISTER_OP_FUNCTION(Linear, CUDA, FLOAT32, cuda_fp32_linear_exec); 会将 cuda_fp32_linear_exec 函数注册为在 CUDA 设备上处理 FP32 数据的 Linear 操作的实现。

3. Layer 动态获取 Function 实例： 当 Layer 需要执行一个操作时，它会向 Worker 请求一个合适的 Function 实例。 Worker （或其辅助的工厂类）会根据当前的设备类型和期望的数据精度，查询 OpRegistry 来获取对应的函数指针。
   
   - FuncRegistry::Get(device, dtype) 方法用于根据设备和数据类型查找已注册的函数指针。如果找不到匹配的实现，它会抛出一个运行时错误。


优点：
1. 高度的可扩展性 (遵循开放/封闭原则)：
   - 支持新硬件/新精度简单： 要为某个操作添加对新硬件或新数据精度的支持，开发者只需要：
     1. 创建一个新的源文件（例如 linear_cpu_fp16.cpp ）。
     2. 在该文件中实现具体的 Function （例如 cpu_fp16_linear_exec ）。
     3. 使用 REGISTER_OP_FUNCTION 宏将这个新实现注册到系统中。
        例如： REGISTER_OP_FUNCTION(Linear, CPU, FLOAT16, cpu_fp16_linear_exec);
   - 无需修改核心代码： 添加新的 Function 实现完全不需要修改 Layer 、 Worker 或 OpRegistry 的现有代码。这使得引擎核心保持稳定，同时易于扩展。

2. 代码清晰与解耦：
   - 职责分离： Layer 定义“做什么”， Function 实现“怎么做”， Registry 负责“找到谁来做”。创建逻辑（选择 Function ）与 Function 的具体实现逻辑完全分离。
   - Worker 和 Layer 的简化： Worker 和 Layer 不需要知道所有具体的 Function 实现类名或包含复杂的 if/else 或 switch 语句来选择实现。它们只需要与抽象的 Function 接口和 Registry 交互。

3. 易于维护和测试：
   - 每个 Function 实现都封装在自己的文件中，便于独立开发、测试和维护。
   - 可以针对特定的设备和数据类型组合进行单元测试。